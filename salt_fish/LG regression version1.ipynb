{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由于经验不足，还是借鉴了网上找的套路，但train与test主要为自己思考\n",
    "#用的为改进版的梯度下降\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sigmoid function  \n",
    "def sigmoid(inX):  \n",
    "    return 1.0 / (1 + np.exp(-inX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():  \n",
    "    train_x =[];train_y =[]\n",
    "    fr = open('salted_fish_train.txt')  \n",
    "    for line in fr.readlines():  \n",
    "        lineArr = line.strip().split()  \n",
    "        if (len(lineArr)==9):   #有数据缺失\n",
    "            train_x.append([1.0, float(lineArr[0]), float(lineArr[1]),float(lineArr[2]),float(lineArr[3]),float(lineArr[4]),float(lineArr[5]),float(lineArr[6]),float(lineArr[7])*0.4])\n",
    "            train_y.append(float(lineArr[8]))\n",
    "    return np.mat(train_x), np.mat(train_y).transpose() \n",
    "# loadDataset主要功能是打开文件salted_fish_train.txt并逐行读取\n",
    "def loadTestSet():  \n",
    "    test_x =[];test_y =[]\n",
    "    fr = open('salted_fish_test.txt')  \n",
    "    for line in fr.readlines():  \n",
    "        lineArr = line.strip().split()  \n",
    "        if (len(lineArr)==9):   #有数据缺失\n",
    "            test_x.append([1.0, float(lineArr[0]), float(lineArr[1]),float(lineArr[2]),float(lineArr[3]),float(lineArr[4]),float(lineArr[5]),float(lineArr[6]),float(lineArr[7])*0.4])\n",
    "            test_y.append(float(lineArr[8]))\n",
    "    return np.mat(test_x), np.mat(test_y).transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y,index):\n",
    "    Samples,Features = np.shape(train_x)\n",
    "    Iter = index['Iter']\n",
    "    alpha =index['alpha']\n",
    "    weights = np.ones((Features, 1)) \n",
    "    for i in range(Iter):\n",
    "    # randomly select samples to optimize for reducing cycle fluctuations   \n",
    "            dataIndex = list(range(Samples))  \n",
    "            for j in range(Samples):  \n",
    "                alpha = 4.0 / (1.0 + i + j) + 0.01  \n",
    "                randIndex = int(random.uniform(0, len(dataIndex)))  \n",
    "                output = sigmoid(train_x[randIndex, :] * weights)  \n",
    "                error = train_y[randIndex, 0] - output  \n",
    "                weights = weights + alpha * train_x[randIndex, :].transpose() * error  \n",
    "                del(dataIndex[randIndex]) # during one interation, delete the optimized sample\n",
    "    return weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(weights, test_x, test_y):\n",
    "    Samples,Features = np.shape(test_x)  \n",
    "    match = 0  \n",
    "    for i in range(Samples):  \n",
    "        predict = sigmoid(test_x[i, :] * weights)[0, 0] > 0.5  \n",
    "        if predict == bool(test_y[i, 0]):  \n",
    "            match += 1  \n",
    "    accuracy = float(match) / Samples  \n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y =loadDataSet()\n",
    "test_x = train_x; test_y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "index = {'alpha': 0.01, 'Iter': 10000}  \n",
    "optimalWeights = train(train_x, train_y,index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classify data_accuracy is: 72.519%\n",
      "The classify test_accuracy is: 71.538%\n"
     ]
    }
   ],
   "source": [
    "data_accuracy = test(optimalWeights, test_x, test_y) \n",
    "test1_x,test1_y=loadTestSet()\n",
    "test_accuracy = test(optimalWeights, test1_x, test1_y) \n",
    "print( 'The classify data_accuracy is: %.3f%%' % (data_accuracy * 100))\n",
    "print( 'The classify test_accuracy is: %.3f%%' % (test_accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
